{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%configure\n",
    "{ \"conf\": {\n",
    "            \"spark.jars\":\"hdfs:///apps/hudi/lib/hudi-spar-bundle.jar,hdfs:///apps/hudi/lib/spark-avro.jar\",\n",
    "            \"spark.serializer\":\"org.apache.spark.serializer.KryoSerializer\",\n",
    "            \"spark.sql.hive.convertMetastoreParquet\":\"false\"\n",
    "          }}\n",
    "\n",
    "import org.apache.hudi.DataSourceWriteOptions\n",
    "import org.apache.hudi.config.HoodieWriteConfig\n",
    "import org.apache.hudi.hive.MultiPartKeysValueExtractor\n",
    "import org.apache.spark.sql.SaveMode\n",
    "\n",
    "val hudiTableName = \"amazon_product_reviews\"\n",
    "val hudiTableRecordKey = \"RECORD_KEY\"\n",
    "val hudiTablePartitionKey = \"PARTITION_KEY\"\n",
    "val hudiTablePrecombineKey = \"review_id\"\n",
    "val hudiTablePath = \"s3://hocanint-reinvent-demo-outputs/createdatasets/\" + hudiTableName\n",
    "\n",
    "val df = spark.read.option(\"sep\", \"\\t\").option(\"header\", \"true\").csv(\"s3://amazon-reviews-pds/tsv/amazon_reviews_us_Home_Improvement_v1_00.tsv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "/** \n",
    "            One time transforamtion of the data \n",
    "**/\n",
    "(df.write.format(\"org.apache.hudi\")\n",
    "  //Merge On Read Storage\n",
    "  .option(DataSourceWriteOptions.STORAGE_TYPE_OPT_KEY, DataSourceWriteOptions.MOR_STORAGE_TYPE_OPT_VAL)\n",
    "  .option(DataSourceWriteOptions.RECORDKEY_FIELD_OPT_KEY, hudiTableRecordKey)\n",
    "  .option(DataSourceWriteOptions.PARTITIONPATH_FIELD_OPT_KEY, hudiTablePartitionKey)\n",
    "  .option(HoodieWriteConfig.TABLE_NAME, hudiTableName)\n",
    "  .option(DataSourceWriteOptions.OPERATION_OPT_KEY, DataSourceWriteOptions.UPSERT_OPERATION_OPT_VAL)\n",
    "  .option(DataSourceWriteOptions.PRECOMBINE_FIELD_OPT_KEY, hudiTablePrecombineKey)\n",
    "  .option(DataSourceWriteOptions.HIVE_SYNC_ENABLED_OPT_KEY, \"true\")\n",
    "  .option(DataSourceWriteOptions.HIVE_TABLE_OPT_KEY,hudiTableName)\n",
    "  .option(DataSourceWriteOptions.HIVE_ASSUME_DATE_PARTITION_OPT_KEY, \"false\")\n",
    "  .option(DataSourceWriteOptions.HIVE_PARTITION_EXTRACTOR_CLASS_OPT_KEY, classOf[MultiPartKeysValueExtractor].getName)\n",
    "  .mode(SaveMode.Append)\n",
    "  .save(hudiTablePath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"marketplace\").filter(\"marketplace == 'US'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}